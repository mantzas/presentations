The Good, the Bad and the Ugly

29 Nov 2018
Tags: go, microservices, patron

Sotirios Mantziaris
Refreshment Engineer (καφετζής)

smantziaris@gmail.com
http://blog.mantziaris.eu
https://github.com/mantzas
https://gr.linkedin.com/in/mantzas
@smantziaris

* aka Go, Microservices and the Patron Framework

* The good

* 
.image img/600px-Go_Logo_Aqua.png

* why?

- easy to learn and operate
- concurrent
- fast build, test and run cycle
- build-in testing
- build-in profiling (pprof)
- cross compilation
- single binary deployment
- a lot of high quality packages out there
- docker friendly

go could be called a "cloud native" language

* 

.image img/gopher.png

* The bad

* Microservices

There is a lot of hype around microservices and they can, if used correctly, solve some problems that exist in a big monolith.

Unfortunately there is much more emphasis on the good sides than the bad ones.

They are no silver bullets.

- Another good point made by Martin Fowler is: 
    
    don’t even consider microservices unless you have a system that’s too complex to manage 
    as a monolith.

* Let's discuss some of the bad ones

* distributed computing is a hard problem

- orchestrate multiple services
- manage deployments
- monitor everything
- [[https://en.wikipedia.org/wiki/CAP_theorem][CAP Theorem]]
    ... due to the fact that network partitioning has to be tolerated 
    there are only Consistency or Availability.
- [[https://en.wikipedia.org/wiki/PACELC_theorem][PACELC theorem (CAP theorem extension)]]
    ... in case of network partitioning (P) in a distributed computer system, 
    one has to choose between availability (A) and consistency (C) (as per the CAP theorem), 
    but else (E), even when the system is running normally in the absence of partitions, 
    one has to choose between latency (L) and consistency (C).

* Fallacies of distributed computing

- The network is reliable.
- Latency is zero.
- Bandwidth is infinite.
- The network is secure.
- Topology doesn't change.
- There is one administrator.
- Transport cost is zero.
- The network is homogeneous.

* Response times (RT) increases (optimistic)

user --> Service A --> Service B --> Service C

where:

    RT Service A: 60ms
    RT Service B: 30ms
    RT Service C: 50ms

Total response time for the user is:

    RT Service C + RT Service B + RT Service A = 140ms

which will be generally bigger than the response time of a monolith due to network, marshal/unmarshal data etc.

* Response times (RT) explodes (pessimistic)

user --> Service A --> Service B --> Service C

where:

    RT Service A: 60ms
    RT Service B: 30ms
    RT Service C: times out at 60s

Total response time for the user is:

    RT Service C + RT Service B + RT Service A = 1m 90ms

which would not happen in a monolith at all!

* Availability decreases

e.g.

    Availability Service A: 99.9%
    Availability Service B: 99.9%
    Availability Service C: 99.9%

the joint availability ([[https://en.wikipedia.org/wiki/Probability#Mathematical_treatment][probability rules]], independent events) for the user is:

    Availability Service A * Availability Service B * Availability Service C ~ 99.7%

Even if all services are 99.9% the joint availability is lower than the individual ones.

The difference is not that small! ([[https://uptime.is/][downtime calculation]])

    99.9 ~ 8h 45m 57.0s downtime
    99.7 ~ 1d 2h 17m 50.9s downtime

* Coupling

[[https://en.wikipedia.org/wiki/Coupling_(computer_programming)][coupling]] is the degree of interdependence between software modules.

how can this happen?

- microservice creation based on opportunity
- shared db
- access the db directly and not through a API
- shared components, like models and business code

the above will lead to what is commonly called a "distributed monolith".

* Indications of a "distributed monolith"?

- A change to one microservice often requires changes to other microservices
- Deploying one microservice requires other microservices to be deployed at the same time
- Your microservices are overly chatty
- The same developers work across a large number of microservices
- Many of your microservices share a data storage
- Your microservices share a lot of the same code or models

* Troubleshooting failures

In order to troubleshoot you have to look into multiple services to find the problem.

- Metrics
    help you identify the general area of a problem e.g. response time is high

- Distributed tracing
    can narrow down the problem e.g. response time of the db is high on service A

- Logging
    can show details tha are logged eg what happened to payment with id xxx

all the above fall under the category of *observability*.

* how can any or all of the previous be avoided?

- DDD can help, e.g. separate bounded contexts
- Observability with logging, metrics, distributed tracing
- Circuit breakers, correct timeouts in place
- Not everything has to be microservices
- Data duplication can be helpful

* The ugly

* The patron framework

Writing all the boilerplate code for a service is cumbersome and gets boring after a few microservices have been created.

Patron

- helps implementing go microservices by abstracting away most of the boilerplate code
- allows to focus on the code that gives the actual value
- tries to incorporate good practices.

* Why this name?

Patron is french for 

- template(blueprint) or pattern
- but it means also boss which we found out later :)

like a sewing pattern for jeans

.image img/jeans.jpg

* Features 1/2

- components available for HTTP (sync), AMQP and Kafka (async)
- structured log, with [[https://github.com/rs/zerolog][zerolog]], to STDOUT
- metrics with [[https://prometheus.io/][prometheus]]
- distributed tracing with [[https://www.jaegertracing.io/][jaeger's]] [[https://opentracing.io/][opentracing]] implementation
- health check via '/health'
- service info available via '/info'
- pprof available via '/debug/pprof'
- metrics available '/metrics'

* Features 2/2

- go mod support
- versioning support
- clients with integrated distributed tracing (http, sql, amqp, kafka)
- clients with timeout support
- patron cli for bootstrapping a service with: 
    docker support
    packages template
    go module and optional vendoring
    git repository creation
    readme creation

* what's next?

- client circuit breaker integration
- consumer groups supported Kafka consumer
- API security abstraction
- protobuf support HTTP
- maybe throttling?
- check out [[https://github.com/mantzas/patron/issues][issues]]

Contributions and ideas are highly welcome!

* Concepts

- The service is the core entity
- A component is managed by the service (run, error handling, cancel)
- A component has to implement the below interface

    type Component interface {
        Run(ctx context.Context) error
        Info() map[string]interface{}
    }

    Run() is used to start a component, context is used to handle cancellation
    Info() is used to describe the component

- check out [[https://github.com/mantzas/patron/blob/master/README.md][README.md]] for more details

* Creating a service

- create a service using patron cli

    patron -p test -m "github.com/mantzas/test"  

since we are using go 1.11+ we do not need to be in the GOPATH... at last...

- In order to run

     go run cmd/test/main.go    

* Show time!

* Demo goals

We create services that

- receive a HTTP POST and publishes a message to Kafka (service a)
- receive the above message, via a async component with Kafka consumer, and publishes a message to RabbitMQ (service b)
- receives the above message, via a async component with AMQP consumer, and logs to STDOUT (service c)

* Prerequisites

- first start all dependent containers (Kafka, RabbitMQ, Jaeger)

    docker-compose up -d

check that kafka has started 

    docker ps | grep kafka

* Run the services

- service a (HTTP -> Kafka)

    PATRON_JAEGER_SAMPLER_PARAM=1.0 go run main.go http.go

- service b (Kafka -> RabbitMQ)

    PATRON_JAEGER_SAMPLER_PARAM=1.0 PATRON_HTTP_DEFAULT_PORT=50001 go run main.go kafka.go

- service c (RabbitMQ -> stdout)

    PATRON_JAEGER_SAMPLER_PARAM=1.0 PATRON_HTTP_DEFAULT_PORT=50002 go run main.go amqp.go       

* Kick of the processing

    curl -i -X POST http://localhost:50000

* Checkout (1/2)

- logs STDOUT    

- service info

    http://localhost:50000/info
    http://localhost:50001/info
    http://localhost:50002/info

- metrics

    http://localhost:50000/metrics
    http://localhost:50001/metrics
    http://localhost:50002/metrics

* Checkout (2/2)

- pprof

    http://localhost:50000/debug/pprof/
    http://localhost:50001/debug/pprof/
    http://localhost:50002/debug/pprof/

- health check

    http://localhost:50000/health
    http://localhost:50001/health
    http://localhost:50002/health


- distributed tracing (jaeger)

    http://localhost:16686/search